# fetch_etl
Data Engineering Take Home: ETL off a SQS Queue

## Installation

### Initalize environment
```bash
git clone git@github.com:aschwa/fetch_etl.git
cd fetch_etl
conda env create  --file environment.yml
docker-compose build
docker-compose up
```
Wait for containers to run.

### Run App (in separate terminal)
```bash
conda activate fetch_env
cd app
uvicorn main:app
```

While app is running, you can visit http://127.0.0.1:8000 to run the app's functionality. 
1. Click the GET button
2. Click "Try it out"
3. Click Execute

### Check database 
```bash
 psql -d postgres -U postgres -p 5432 -h localhost -W
```
```sql
select * from user_logins;
```

## Design Questions

* How will you read messages from the queue?

Messages are read from the queue via `localstack_client` which allows a local client to run similarly to `boto3`. The messages are then loaded into dictionaries via `json.loads`, which can then be processed.
* What type of data structures should be used?

I created a `UserLogin` class based on `pydantic`'s  `BaseModel`. This would be useful down the road for additional processing and validation of the login events. 

* How will you mask the PII data so that duplicate values can be identified?

I use Fernet to encrypt the PII data. We can use a key that is stored securely to decrpyt the data, or just check that the encrypted value is unique to detect duplicates. I include the same Fernet key in settings in case we wanted to test the decryption.

* What will be your strategy for connecting and writing to Postgres?

I use `psycopg2` to connect and write to Postgres. With additional development time I would consider using `SQLAlchemy` to reflect the database schema in the `user_logins` table.
* Where and how will your application run?

I decided to create a FastAPI application to give the application a simple structure and a quick way to have a GUI via `Swagger UI`. FastAPI is run locally via Uvicorn. Again, this may have been overkill since we really only have one action/API route, but I wanted to make something that could theoretically be built-out with additional functionality.

## Questions

*  How would you deploy this application in production?

I would push this image to a Docker Container registry such as Amazon ECR. It could then be deployed via a container orchestration service or managed Kubernetes service. 

*  What other components would you want to add to make this production ready?

We would need to add functionality for the app to automatically check for logins, rather than rely on the FastAPI GUI (which is really just for debugging).

I would want to add integration tests and structured logging. Integration tests could help ensure that all of the pieces of the app connect together. Structured logging would make debugging deployments easier. 

*  How can this application scale with a growing dataset?

We could scale the application with a service such as Kubernetes and have multiple instances of the application running. We would also want to monitor the app with a service like Amazon CloudWatch to collect metrics on the app.

*  How can PII be recovered later on?

The PII can be decrypted using the key generated by `Fernet`. The key is stored directly in the app here for convienece/proof of concept, but in practice would be stored securely via a Secrets Manager.

*  What are the assumptions you made?

I assumed that the only optional field in UserLogins was `locale`. In my testing I found that the other fields were always present. In practice, I would have gotten a clearer specification of what fields were required vs. optional and also clearer validation rules on the incoming data. I also assumed that the service would only want to read and write out one message from SQS at a time, but in practice this could be done in batches.

I assumed the `create_date` field was when the message was read rather the login occurred. I also assumed `app_version` in the database was the version of this app rather than where the logins were originating.


## Other Next steps
1. More careful handling on receiving and then deleting messages with error handling
2. Custom logging
3. Organize the app to receive http requests
4. Additional validation on UserLogin Class.
5. Add additional unit tests and integration tests.
6. Deployment via kubernetes
7. Consider mirroring the sql ORM
8. Automated versioning. Could use a tool like `bumpversion`